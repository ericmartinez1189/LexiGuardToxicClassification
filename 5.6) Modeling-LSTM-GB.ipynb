{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling GRADIENT BOOSTING and LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImportS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import spacy\n",
    "import ast\n",
    "import joblib\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this initialize tqdm which is useful to show a progress bar when applying operations in a pandas df\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/data_usampl_60_40_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['raw', 'clean', 'clean_pp', 'clean_pp_lemma', 'clean_pp_lemma_stop',\n",
       "       'toxic'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to include results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe that will include the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "def evaluate_model(model, X_train,y_train,X_test,y_test, model_name=\"\", parameters='', comments=''):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    duration = time.time() - start_time\n",
    "    duration_format = f\"{int(duration // 60)} minutes and {round(duration % 60, 2)} seconds\"\n",
    "    predicted_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics using probabilities\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_probs)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    conf_matrix = str(confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # Create a dictionary including the results\n",
    "    results = {\n",
    "        'Name': model_name if model_name else model.__class__.__name__,\n",
    "        'Parameters': parameters,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Training Time': duration_format,\n",
    "        'Comments': comments\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df['clean_pp_lemma']\n",
    "y = df['toxic']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Name Parameters  F1-Score   AUC-ROC  Precision  \\\n",
      "0  Gradient Boosting Classifier     TF-IDF  0.576923  0.736484   0.882353   \n",
      "\n",
      "     Recall  Accuracy     Confusion Matrix               Training Time  \\\n",
      "0  0.428571      0.78  [[63  2]\\n [20 15]]  0 minutes and 1.57 seconds   \n",
      "\n",
      "  Comments  \n",
      "0           \n"
     ]
    }
   ],
   "source": [
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Evaluate Gradient Boosting Classifier using evaluate_model function\n",
    "results_gb = evaluate_model(gb_classifier, X_train_tfidf, y_train, X_test_tfidf, y_test, model_name=\"Gradient Boosting Classifier\", parameters=\"TF-IDF\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df_gb = pd.DataFrame([results_gb])\n",
    "\n",
    "# Concatenate the new results DataFrame to the existing one\n",
    "results_df = pd.concat([results_df, results_df_gb], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.736484</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.78</td>\n",
       "      <td>[[63  2]\\n [20 15]]</td>\n",
       "      <td>0 minutes and 1.57 seconds</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Parameters  F1-Score   AUC-ROC  Precision  \\\n",
       "0  Gradient Boosting Classifier     TF-IDF  0.576923  0.736484   0.882353   \n",
       "\n",
       "     Recall  Accuracy     Confusion Matrix               Training Time  \\\n",
       "0  0.428571      0.78  [[63  2]\\n [20 15]]  0 minutes and 1.57 seconds   \n",
       "\n",
       "  Comments  \n",
       "0           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X = df['clean_pp_lemma'].values # Extract the input feature 'clean_pp_lemma'\n",
    "y = df['toxic'].values # Extract the target variable 'toxic'\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Here, 80% of data is used for training and 20% for testing. Random state ensures reproducibility.\n",
    "\n",
    "# Tokenize and convert text to sequences\n",
    "max_words = 10000  # Set the maximum number of words to consider in the vocabulary\n",
    "max_len = 100  # Set the maximum length of each sequence\n",
    "tokenizer = Tokenizer(num_words=max_words) # Initialize the Tokenizer\n",
    "tokenizer.fit_on_texts(X_train) # Fit the tokenizer on the training data\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train) # Convert training text to sequences of integers\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test) # Convert test text to sequences of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer to a file\n",
    "tokenizer_file_path = 'data/tokenizer.pkl'\n",
    "with open(tokenizer_file_path, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# The tokenizer is saved to a file for later use (e.g., during model deployment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)  # Pad/truncate training sequences\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len) # Pad/truncate test sequences\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential() # Initialize the Sequential model\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len)) # Add embedding layer\n",
    "model.add(LSTM(units=64)) # Add LSTM layer with 64 units\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Add output layer with sigmoid activation for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 3s 102ms/step - loss: 0.6751 - accuracy: 0.6200 - val_loss: 0.6394 - val_accuracy: 0.6500\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.6217 - accuracy: 0.6450 - val_loss: 0.6277 - val_accuracy: 0.6500\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5654 - accuracy: 0.6625 - val_loss: 0.6051 - val_accuracy: 0.6500\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.4055 - accuracy: 0.7750 - val_loss: 0.5806 - val_accuracy: 0.7100\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 1s 73ms/step - loss: 0.2256 - accuracy: 0.9800 - val_loss: 0.6154 - val_accuracy: 0.6500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f126bb3850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Compile the model with binary crossentropy loss and adam optimizer\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "# Train the model for 5 epochs with a batch size of 32, using validation data for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('data/model5.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('data/model_weights5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 10ms/step\n",
      "4/4 [==============================] - 0s 12ms/step\n",
      "Accuracy: 0.65\n",
      "Precision: 0.5\n",
      "Recall: 0.7714285714285715\n",
      "F1 Score: 0.6067415730337079\n",
      "AUC-ROC: 0.7296703296703297\n",
      "Confusion Matrix:\n",
      "[[38 27]\n",
      " [ 8 27]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "y_pred = (model.predict(X_test_padded) > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test_padded))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUC-ROC: {roc_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ee5ce8695951d3743acb1574d7cbc518a435066b16546d59d44a9748127e061"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
